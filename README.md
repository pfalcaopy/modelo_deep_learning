# ğŸ§  ClassificaÃ§Ã£o Inteligente de Textos Financeiros com Deep Learning e GitHub Actions

Imagine ter milhares de registros financeiros â€” cada linha, um fragmento de texto com descriÃ§Ãµes, fornecedores e categorias.  
Agora imagine transformar essa massa de informaÃ§Ãµes em **conhecimento estruturado**, de forma **automÃ¡tica**, **inteligente** e **constante**.  

Foi com esse propÃ³sito que nasceu este projeto.

---

## ğŸŒ± A Ideia

O desafio comeÃ§ou simples: **categorizar automaticamente textos financeiros** de um extrato.  
Mas a ambiÃ§Ã£o era maior â€” **criar um sistema autÃ´nomo**, capaz de:
- Aprender com novos dados do banco de dados;
- Se treinar novamente de forma automÃ¡tica;
- E manter o modelo sempre atualizado, sem intervenÃ§Ã£o manual.

Assim, unimos **Deep Learning** com **automaÃ§Ã£o em nuvem via GitHub Actions**.

---

## âš™ï¸ O CoraÃ§Ã£o do Projeto â€” O Modelo de Deep Learning

O arquivo [`model.py`](model.py) Ã© o cÃ©rebro do sistema.

Ele inicia com uma conexÃ£o direta ao banco PostgreSQL, carregando os dados da tabela.  
A partir daÃ­, o texto Ã© transformado em algo que uma rede neural possa entender.

### ğŸ§© PrÃ©-processamento e CriaÃ§Ã£o do Texto Unificado
Cada linha do extrato Ã© reconstruÃ­da como uma narrativa Ãºnica:
```text
tipo_operacao + categoria + fornecedor + descricao + instituicao + categoria_financeira
```
Essas informaÃ§Ãµes sÃ£o convertidas para minÃºsculas e limpas, formando uma base textual rica em contexto.

### ğŸ”¢ Transformando Texto em Vetores
Utilizamos o poder do **TextVectorization** do TensorFlow:
```python
vectorizer = TextVectorization(max_tokens=5000, output_mode='int', output_sequence_length=100)
```
Isso converte palavras em nÃºmeros â€” a linguagem que as redes neurais compreendem.

---

## ğŸ§¬ A Arquitetura Neural

Para capturar o "ritmo" e a sequÃªncia das palavras, foi usada uma **rede recorrente LSTM (Long Short-Term Memory)**, capaz de compreender contexto e dependÃªncias entre termos.

```python
model = keras.Sequential([
    Embedding(input_dim=5000, output_dim=16, mask_zero=True),
    LSTM(64, return_sequences=True),
    LSTM(32),
    Dense(32, activation='relu'),
    Dense(num_classes, activation='softmax')
])
```

Essa arquitetura foi escolhida por equilibrar **profundidade e eficiÃªncia**, garantindo uma aprendizagem rÃ¡pida e precisa mesmo com dados textuais complexos.

---

## ğŸ“ˆ O Aprendizado

Durante o treinamento, o modelo aprendeu a reconhecer padrÃµes com velocidade impressionante.  
Nas primeiras Ã©pocas, a acurÃ¡cia jÃ¡ ultrapassava **90%**, e logo alcanÃ§ou **quase 100%**, tanto no treino quanto na validaÃ§Ã£o.  
A perda (loss) caiu drasticamente nas primeiras iteraÃ§Ãµes e estabilizou prÃ³xima de zero â€” sinal de **convergÃªncia ideal** e **excelente generalizaÃ§Ã£o**.

Esses resultados mostraram que a arquitetura, os hiperparÃ¢metros e o prÃ©-processamento estavam em harmonia.

---

## ğŸ’¾ A PersistÃªncia do Conhecimento

ApÃ³s o treinamento:
- O modelo Ã© salvo como `modelo_classificacao.h5`;
- O codificador de rÃ³tulos (`LabelEncoder`) Ã© salvo como `label_encoder.pkl`.

Esses arquivos tornam possÃ­vel aplicar o modelo em produÃ§Ã£o, classificando novos textos em tempo real.

---

## ğŸ¤– A AutomaÃ§Ã£o com GitHub Actions

O toque de mestre do projeto estÃ¡ no arquivo [`run-model.yaml`](run-model.yaml).  
Ele transforma o modelo em uma **entidade viva**, que se autoatualiza a cada 15 dias.

### ğŸ”„ Workflow Automatizado
```yaml
on:
  schedule:
    - cron: "0 0 */15 * *"  # Executa a cada 15 dias
  workflow_dispatch: {}
```

O GitHub Actions:
1. Baixa o repositÃ³rio;
2. Instala as dependÃªncias do [`requirements.txt`](requirements.txt);
3. Executa `python model.py` automaticamente.

Assim, a cada ciclo, o modelo Ã© re-treinado com os **dados mais recentes** do banco, garantindo decisÃµes cada vez mais alinhadas com a realidade financeira.

---

## ğŸ§© Tecnologias que Deram Vida ao Projeto

| Camada | Ferramenta |
|--------|-------------|
| Deep Learning | TensorFlow / Keras |
| Dados | Pandas, NumPy, SQLAlchemy |
| Banco de Dados | PostgreSQL |
| AutomaÃ§Ã£o | GitHub Actions |
| Linguagem | Python 3.11 |
| Utilidades | dotenv, scikit-learn, matplotlib |

---

## ğŸ§ª Resultados e Impacto

O modelo mostrou **excelente desempenho**:
- AcurÃ¡cia de validaÃ§Ã£o prÃ³xima de 100%;
- Perda mÃ­nima apÃ³s poucas Ã©pocas;
- Estabilidade em diferentes execuÃ§Ãµes.

Esses resultados indicam que o sistema **compreende profundamente a linguagem financeira** e estÃ¡ pronto para operaÃ§Ã£o contÃ­nua.

---

## ğŸ‘¨â€ğŸ’» Autor

**ğŸ§”ğŸ» Pedro FalcÃ£o**  
ğŸ§© Engenheiro de Dados  
ğŸ’¡  ETL, Eng. de dados, Analise de dados inteligente e sistemas autÃ´nomos  
ğŸ“§ pfalcao.py@gmail.com

---

## ğŸ•’ Em resumo

> Este projeto nÃ£o Ã© apenas um modelo de classificaÃ§Ã£o â€”  
> Ã© um **organismo digital** que aprende, evolui e se mantÃ©m atualizado sozinho.  
> Um exemplo real de como a inteligÃªncia artificial pode se integrar perfeitamente ao ciclo de automaÃ§Ã£o moderna.

---

ğŸ“œ **Os dados contÃªm uma histÃ³ria; nossa missÃ£o Ã© narrÃ¡-las.** Pedro FalcÃ£o
